% Appendix A
% For referencing this appendix elsewhere, use \ref{AppendixA}
\chapter{Methods} % Main appendix title
\label{Appendix-methods} 

This appendix details procedures used to carry out the experiments

\section{conda}
\label{app_methods:conda}

conda commands used in this project:
% Another good simplified reference
% https://docs.conda.io/projects/conda/en/latest/commands.html

\begin{verbatim}
# List conda environments
$ conda info --envs
# Activate conda - conda environment appears in parenthesis on command prompt
$ conda activate
# Deactivate conda
$ conda deactivate
# Create and activate environment
$ conda create --name cleargrasp
$ conda activate cleargrasp
# list modules
$ conda list
\end{verbatim}

\section{ClearGrasp Install - Ubuntu 19.04}

For this project, ClearGrasp was originally deployed to an AWS (\cite{amazon2015amazon}) cloud EC2 server at the proof-of-concept stage, following the procedure described in \cite{cleargrasp-install2020}. For the actual work, using the Zivid One+ camera, ClearGrasp was deployed to a physical workstation: Dell Precison Tower 5810 with a 12-core Intel Xeon processor E5-1600 v3 and 32MB RAM. Given some software was already present, the procedure was simplified to:
\begin{verbatim}
# create conda environment
$ conda create --name cleargrasp
$ conda activate cleargrasp
# change python simlynk to point to v3.6.9
$ sudo ln -s /usr/bin/python3.6 /usr/bin/python
# install libraries
$ sudo apt-get install -y libhdf5-10 libhdf5-serial-dev libhdf5-dev libhdf5-cpp-11
$ sudo apt install -y libopenexr-dev zlib1g-dev openexr
$ sudo apt install -y xorg-dev  # display widows
$ sudo apt install -y libglfw3-dev
# clone repository
$ git clone git@github.com:Shreeyak/cleargrasp.git
$ cd cleargrasp
# download model checkpoints
$ wget http://clkgum.com/shreeyak/cleargrasp-checkpoints 
$ mv cleargrasp-checkpoints cleargrasp-checkpoints.zip
$ unzip cleargrasp-checkpoints.zip
$ mv cleargrasp-checkpoints data
# requirements
$ wget https://raw.githubusercontent.com/dsikar/cleargrasp/master/requirements_v2.txt
$ pip install -r requirements_v2.txt
# depth2depth compilation as per step 4 in https://github.com/Shreeyak/cleargrasp
# Install open3d
$ pip install open3d --no-cache-dir
# copy config file
$ cd eval_depth_completion/
$ cp config/config.yaml.sample config/config.yaml
# run evaluation
$ python eval_depth_completion.py -c config/config.yaml
\end{verbatim}

\section{ClearGrasp Install - Ubuntu 20.04}

Check Python version:
\begin{verbatim}
$ python --version
Python 3.8.5    
\end{verbatim}
Since Python is version 3.x, the symlink will not be required. Download Anaconda:
\begin{verbatim}
$ wget https://repo.anaconda.com/archive/Anaconda3-2020.11-Linux-x86_64.sh    
\end{verbatim}
Install:
\begin{verbatim}
$ bash Anaconda3-2020.11-Linux-x86_64.sh    
\end{verbatim}
Terminal restart (required), then, as with Ubuntu 19.04 install:
\begin{verbatim}
# List conda environments
$ conda info --envs
# Create and activate environment
$ conda create --name cleargrasp
$ conda activate cleargrasp
\end{verbatim}
And continue with setup:
\begin{verbatim}
# update and install
$ sudo apt update
$ sudo apt --fixed-broken install
\end{verbatim}
There are a couple of libraries missing:
\begin{verbatim}
E: Unable to locate package lbhdf5-10
E: Unable to locate package libhdf5-cpp-11
\end{verbatim}
This could be a problem. Next we run a modified version of the requirements\_v2.txt (dsikar/cleargrasp.git). Also threw an error, fixed by installing opencv-python and commenting out corresponding line in requirements\_v2.txt:
\begin{verbatim}
$ pip install opencv-python
opencv-python==4.1.1.26

\end{verbatim}

\section{Unity Robotics packages}

This section covers the installation of the Unity Robotics packages. As described in \url{https://github.com/Unity-Technologies/Unity-Robotics-Hub}, using version 2020.2.0+. This is done in Ubuntu by obtaining the Unity Hub link at \url{https://unity3d.com/get-unity/download/archive}, and starting unity from the command line, with the unityhub url as a parameter:
\begin{verbatim}
$ sudo ./UnityHub.AppImage unityhub://2020.2.3f1/8ff31bc5bf5b --no-sandbox 
\end{verbatim}

\section{NVIDIA GPU driver installation}

The hardware used in this study consisted of a Dell Precision T5810 Xeon 12-core 32GB RAM.
\begin{itemize}
    \item Zivid One+ RGB-D camera
    \item Dell Precision T5810 Xeon 12-core 32GB RAM Ubuntu 18.04 workstation
    \item NVIDIA GeForce GTX 1060 6GB video card
\end{itemize}

The workstation was originally equipped with a NVIDIA gm206glm Quatro M2200. The cards were swapped and video drivers failed to load, which was rectified with a Ubuntu reinstall.
Zivid studio was installed following the official \href{https://zivid.atlassian.net/wiki/spaces/ZividKB/pages/59080712/Zivid+Software+Installation}{documentation}, in short:
\begin{verbatim}
 # Installing NVIDIA GPU drivers
 $ sudo add-apt-repository ppa:graphics-drivers/ppa
 $ sudo apt install nvidia-driver-430
 # checking number of platforms
 $ sudo apt install -y clinfo
 $ /usr/bin/clinfo
Number of platforms                               1
(...)
\end{verbatim}

\section{Zivid Studio and Python module installation}
Once the NVIDIA drivers are configured, Zivid Studio and Python modules can be installed:
\begin{verbatim}
# Installing zivid studio
$ wget -i https://www.zivid.com/hubfs/softwarefiles/releases/2.2.0+f0867d62-1/u16/ZividInstall1604.txt
$ sudo dpkg -i *.deb
# Zivid Studio can now be run by search zivid on ubuntu start 

# clang might be required, if pip install of zivid is not adding it
$ sudo apt install clang --fix-missing
$ clang --version
(...)

# Python - must be 3.6.+ and pip 19.+, also alias python3 to python and pip3 to pip 
# for good measure

# update pip if necessary
$ python -m pip install -U pip
(...)

# Install
# pip install zivid    
\end{verbatim}

\section{Zivid One+ Capture}
\begin{verbatim}
 todo
1. link to python libs
2. examples
   
\end{verbatim}


\section{PyCharm}
\begin{verbatim}
 Install 
run
. pycharm.sh (downloads)   
\end{verbatim}


\section{PyTorch}

We use PyTorch to load pre-trained models and make inferences (predictions).
To visualise the geometry of the networks, the followin gode may be used.
\begin{verbatim}
# Tensorflow equivalent summary:
# https://stackoverflow.com/questions/42480111/model-summary-in-pytorch
# https://stackoverflow.com/questions/49201236/check-the-total-number-of-parameters-in-a-pytorch-model

# libraries
from __future__ import print_function
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import numpy as np
import matplotlib.pyplot as plt

# LeNet Model definition
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)
        
# Define what device we are using
print("CUDA Available: ",torch.cuda.is_available())
device = torch.device("cuda" if (use_cuda and torch.cuda.is_available()) else "cpu")

# Initialize the network
model = Net().to(device)

# Load the pretrained model
model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))     

# now show the model
from prettytable import PrettyTable

def count_parameters(model):
    table = PrettyTable(["Modules", "Parameters"])
    total_params = 0
    for name, parameter in model.named_parameters():
        if not parameter.requires_grad: continue
        param = parameter.numel()
        table.add_row([name, param])
        total_params+=param
    print(table)
    print(f"Total Trainable Params: {total_params}")
    return total_params

# Layers
print(model) 
# Parameters per layer  
count_parameters(model)
print("")
pytorch_total_params = sum(p.numel() for p in model.parameters())
print("Total number of parameters: ", pytorch_total_params)
pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print("Total number of trainable parameters: ", pytorch_total_params)

# Output
Net(
  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (conv2_drop): Dropout2d(p=0.5, inplace=False)
  (fc1): Linear(in_features=320, out_features=50, bias=True)
  (fc2): Linear(in_features=50, out_features=10, bias=True)
)
+--------------+------------+
|   Modules    | Parameters |
+--------------+------------+
| conv1.weight |    250     |
|  conv1.bias  |     10     |
| conv2.weight |    5000    |
|  conv2.bias  |     20     |
|  fc1.weight  |   16000    |
|   fc1.bias   |     50     |
|  fc2.weight  |    500     |
|   fc2.bias   |     10     |
+--------------+------------+
Total Trainable Params: 21840

Total number of parameters:  21840
Total number of trainable parameters:  21840

What this does not tell us is the input size for the first convolutional layer,
as would be given with Tensorflow summary() method.

Another option:
# https://github.com/sksq96/pytorch-summary
# pip install torchsummary or
# git clone https://github.com/sksq96/pytorch-summary
# from torchsummary import summary
# summary(your_model, input_size=(channels, H, W))

# !pip install torchsummary
from torchsummary import summary
summary(model, input_size=(1, 28, 28))

----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 10, 24, 24]             260
            Conv2d-2             [-1, 20, 8, 8]           5,020
         Dropout2d-3             [-1, 20, 8, 8]               0
            Linear-4                   [-1, 50]          16,050
            Linear-5                   [-1, 10]             510
================================================================
Total params: 21,840
Trainable params: 21,840
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.06
Params size (MB): 0.08
Estimated Total Size (MB): 0.15
----------------------------------------------------------------

Another option:
# !pip install torchinfo

from torchinfo import summary

batch_size = 1
summary(model, input_size=(batch_size, 1, 28, 28))
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Conv2d: 1-1                            [1, 10, 24, 24]           260
├─Conv2d: 1-2                            [1, 20, 8, 8]             5,020
├─Dropout2d: 1-3                         [1, 20, 8, 8]             --
├─Linear: 1-4                            [1, 50]                   16,050
├─Linear: 1-5                            [1, 10]                   510
==========================================================================================
Total params: 21,840
Trainable params: 21,840
Non-trainable params: 0
Total mult-adds (M): 0.48
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.06
Params size (MB): 0.09
Estimated Total Size (MB): 0.15
==========================================================================================

In both cases, it is missing the input layer dimensions, as given by TensorFlow summary().
That would make the output similar to:

----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Input                   [1, 28, 28]               0
            Conv2d-1           [-1, 10, 24, 24]             260
            Conv2d-2             [-1, 20, 8, 8]           5,020
            
The code can probably be modified to do so, time allowing. Also, it is worth stressing
that with PyTorch, to obtain the network geometry and number of parameters, a forward
pass is required.

\section{InferenceNormals}

Here we look at the Normal Estimation network.

If we place a breakpoint in inference_models.py, class InferenceNormals(), method
runOnNumpyImage(self, img), we can print the network architecture

print(self.model)
DeepLab(
  (backbone): DRN(
    (layer0): Sequential(
      (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      (1): SynchronizedBatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer1): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer2): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer6): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer7): Sequential(
      (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
      (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer8): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (aspp): ASPP(
    (aspp1): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (aspp2): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (aspp3): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (aspp4): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (global_avg_pool): Sequential(
      (0): AdaptiveAvgPool2d(output_size=(1, 1))
      (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU()
    )
    (conv1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (decoder): Decoder(
    (conv1): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): SynchronizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
    (last_conv): Sequential(
      (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.0, inplace=False)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
    )

To get the number of parameters:

summary(self.model, input_size=(1, 3, 144, 256))
Out[9]: 
=========================================================================================================
Layer (type:depth-idx)                                  Output Shape              Param #
=========================================================================================================
├─DRN: 1-1                                              [1, 512, 18, 32]          --
|    └─Sequential: 2-1                                  [1, 16, 144, 256]         --
|    |    └─Conv2d: 3-1                                 [1, 16, 144, 256]         2,352
|    |    └─SynchronizedBatchNorm2d: 3-2                [1, 16, 144, 256]         32
|    |    └─ReLU: 3-3                                   [1, 16, 144, 256]         --
|    └─Sequential: 2-2                                  [1, 16, 144, 256]         --
|    |    └─Conv2d: 3-4                                 [1, 16, 144, 256]         2,304
|    |    └─SynchronizedBatchNorm2d: 3-5                [1, 16, 144, 256]         32
|    |    └─ReLU: 3-6                                   [1, 16, 144, 256]         --
|    └─Sequential: 2-3                                  [1, 32, 72, 128]          --
|    |    └─Conv2d: 3-7                                 [1, 32, 72, 128]          4,608
|    |    └─SynchronizedBatchNorm2d: 3-8                [1, 32, 72, 128]          64
|    |    └─ReLU: 3-9                                   [1, 32, 72, 128]          --
|    └─Sequential: 2-4                                  [1, 256, 36, 64]          --
|    |    └─Bottleneck: 3-10                            [1, 256, 36, 64]          64,768
|    |    └─Bottleneck: 3-11                            [1, 256, 36, 64]          70,400
|    |    └─Bottleneck: 3-12                            [1, 256, 36, 64]          70,400
|    └─Sequential: 2-5                                  [1, 512, 18, 32]          --
|    |    └─Bottleneck: 3-13                            [1, 512, 18, 32]          379,392
|    |    └─Bottleneck: 3-14                            [1, 512, 18, 32]          280,064
|    |    └─Bottleneck: 3-15                            [1, 512, 18, 32]          280,064
|    |    └─Bottleneck: 3-16                            [1, 512, 18, 32]          280,064
|    └─Sequential: 2-6                                  [1, 1024, 18, 32]         --
|    |    └─Bottleneck: 3-17                            [1, 1024, 18, 32]         1,512,448
|    |    └─Bottleneck: 3-18                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-19                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-20                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-21                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-22                            [1, 1024, 18, 32]         1,117,184
|    └─Sequential: 2-7                                  [1, 2048, 18, 32]         --
|    |    └─Bottleneck: 3-23                            [1, 2048, 18, 32]         6,039,552
|    |    └─Bottleneck: 3-24                            [1, 2048, 18, 32]         4,462,592
|    |    └─Bottleneck: 3-25                            [1, 2048, 18, 32]         4,462,592
|    └─Sequential: 2-8                                  [1, 512, 18, 32]          --
|    |    └─Conv2d: 3-26                                [1, 512, 18, 32]          9,437,184
|    |    └─SynchronizedBatchNorm2d: 3-27               [1, 512, 18, 32]          1,024
|    |    └─ReLU: 3-28                                  [1, 512, 18, 32]          --
|    └─Sequential: 2-9                                  [1, 512, 18, 32]          --
|    |    └─Conv2d: 3-29                                [1, 512, 18, 32]          2,359,296
|    |    └─SynchronizedBatchNorm2d: 3-30               [1, 512, 18, 32]          1,024
|    |    └─ReLU: 3-31                                  [1, 512, 18, 32]          --
├─ASPP: 1-2                                             [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-10                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-32                                [1, 256, 18, 32]          131,072
|    |    └─SynchronizedBatchNorm2d: 3-33               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-34                                  [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-11                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-35                                [1, 256, 18, 32]          1,179,648
|    |    └─SynchronizedBatchNorm2d: 3-36               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-37                                  [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-12                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-38                                [1, 256, 18, 32]          1,179,648
|    |    └─SynchronizedBatchNorm2d: 3-39               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-40                                  [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-13                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-41                                [1, 256, 18, 32]          1,179,648
|    |    └─SynchronizedBatchNorm2d: 3-42               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-43                                  [1, 256, 18, 32]          --
|    └─Sequential: 2-14                                 [1, 256, 1, 1]            --
|    |    └─AdaptiveAvgPool2d: 3-44                     [1, 512, 1, 1]            --
|    |    └─Conv2d: 3-45                                [1, 256, 1, 1]            131,072
|    |    └─SynchronizedBatchNorm2d: 3-46               [1, 256, 1, 1]            512
|    |    └─ReLU: 3-47                                  [1, 256, 1, 1]            --
|    └─Conv2d: 2-15                                     [1, 256, 18, 32]          327,680
|    └─SynchronizedBatchNorm2d: 2-16                    [1, 256, 18, 32]          512
|    └─ReLU: 2-17                                       [1, 256, 18, 32]          --
|    └─Dropout: 2-18                                    [1, 256, 18, 32]          --
├─Decoder: 1-3                                          [1, 3, 36, 64]            --
|    └─Conv2d: 2-19                                     [1, 48, 36, 64]           12,288
|    └─SynchronizedBatchNorm2d: 2-20                    [1, 48, 36, 64]           96
|    └─ReLU: 2-21                                       [1, 48, 36, 64]           --
|    └─Sequential: 2-22                                 [1, 3, 36, 64]            --
|    |    └─Conv2d: 3-48                                [1, 256, 36, 64]          700,416
|    |    └─SynchronizedBatchNorm2d: 3-49               [1, 256, 36, 64]          512
|    |    └─ReLU: 3-50                                  [1, 256, 36, 64]          --
|    |    └─Dropout: 3-51                               [1, 256, 36, 64]          --
|    |    └─Conv2d: 3-52                                [1, 256, 36, 64]          589,824
|    |    └─SynchronizedBatchNorm2d: 3-53               [1, 256, 36, 64]          512
|    |    └─ReLU: 3-54                                  [1, 256, 36, 64]          --
|    |    └─Conv2d: 3-55                                [1, 3, 36, 64]            771
=========================================================================================================
Total params: 40,732,435
Trainable params: 40,732,435
Non-trainable params: 0
Total mult-adds (G): 24.74
=========================================================================================================
Input size (MB): 0.44
Forward/backward pass size (MB): 316.79
Params size (MB): 162.93
Estimated Total Size (MB): 480.17
=========================================================================================================


\end{verbatim}

\section{inferenceMasks}

Here we look at details of the Transparent Objectc Segmentation network

\begin{verbatim}

print(self.model)
DeepLab(
  (backbone): DRN(
    (layer0): Sequential(
      (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      (1): SynchronizedBatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer1): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer2): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer6): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer7): Sequential(
      (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
      (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer8): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (aspp): ASPP(
    (aspp1): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (aspp2): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (aspp3): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (aspp4): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (global_avg_pool): Sequential(
      (0): AdaptiveAvgPool2d(output_size=(1, 1))
      (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU()
    )
    (conv1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (decoder): Decoder(
    (conv1): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): SynchronizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
    (last_conv): Sequential(
      (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.1, inplace=False)
      (8): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)

summary(self.model, input_size=(1, 3, 144, 256))
Out[3]: 
=========================================================================================================
Layer (type:depth-idx)                                  Output Shape              Param #
=========================================================================================================
├─DRN: 1-1                                              [1, 512, 18, 32]          --
|    └─Sequential: 2-1                                  [1, 16, 144, 256]         --
|    |    └─Conv2d: 3-1                                 [1, 16, 144, 256]         2,352
|    |    └─SynchronizedBatchNorm2d: 3-2                [1, 16, 144, 256]         32
|    |    └─ReLU: 3-3                                   [1, 16, 144, 256]         --
|    └─Sequential: 2-2                                  [1, 16, 144, 256]         --
|    |    └─Conv2d: 3-4                                 [1, 16, 144, 256]         2,304
|    |    └─SynchronizedBatchNorm2d: 3-5                [1, 16, 144, 256]         32
|    |    └─ReLU: 3-6                                   [1, 16, 144, 256]         --
|    └─Sequential: 2-3                                  [1, 32, 72, 128]          --
|    |    └─Conv2d: 3-7                                 [1, 32, 72, 128]          4,608
|    |    └─SynchronizedBatchNorm2d: 3-8                [1, 32, 72, 128]          64
|    |    └─ReLU: 3-9                                   [1, 32, 72, 128]          --
|    └─Sequential: 2-4                                  [1, 256, 36, 64]          --
|    |    └─Bottleneck: 3-10                            [1, 256, 36, 64]          64,768
|    |    └─Bottleneck: 3-11                            [1, 256, 36, 64]          70,400
|    |    └─Bottleneck: 3-12                            [1, 256, 36, 64]          70,400
|    └─Sequential: 2-5                                  [1, 512, 18, 32]          --
|    |    └─Bottleneck: 3-13                            [1, 512, 18, 32]          379,392
|    |    └─Bottleneck: 3-14                            [1, 512, 18, 32]          280,064
|    |    └─Bottleneck: 3-15                            [1, 512, 18, 32]          280,064
|    |    └─Bottleneck: 3-16                            [1, 512, 18, 32]          280,064
|    └─Sequential: 2-6                                  [1, 1024, 18, 32]         --
|    |    └─Bottleneck: 3-17                            [1, 1024, 18, 32]         1,512,448
|    |    └─Bottleneck: 3-18                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-19                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-20                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-21                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-22                            [1, 1024, 18, 32]         1,117,184
|    └─Sequential: 2-7                                  [1, 2048, 18, 32]         --
|    |    └─Bottleneck: 3-23                            [1, 2048, 18, 32]         6,039,552
|    |    └─Bottleneck: 3-24                            [1, 2048, 18, 32]         4,462,592
|    |    └─Bottleneck: 3-25                            [1, 2048, 18, 32]         4,462,592
|    └─Sequential: 2-8                                  [1, 512, 18, 32]          --
|    |    └─Conv2d: 3-26                                [1, 512, 18, 32]          9,437,184
|    |    └─SynchronizedBatchNorm2d: 3-27               [1, 512, 18, 32]          1,024
|    |    └─ReLU: 3-28                                  [1, 512, 18, 32]          --
|    └─Sequential: 2-9                                  [1, 512, 18, 32]          --
|    |    └─Conv2d: 3-29                                [1, 512, 18, 32]          2,359,296
|    |    └─SynchronizedBatchNorm2d: 3-30               [1, 512, 18, 32]          1,024
|    |    └─ReLU: 3-31                                  [1, 512, 18, 32]          --
├─ASPP: 1-2                                             [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-10                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-32                                [1, 256, 18, 32]          131,072
|    |    └─SynchronizedBatchNorm2d: 3-33               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-34                                  [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-11                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-35                                [1, 256, 18, 32]          1,179,648
|    |    └─SynchronizedBatchNorm2d: 3-36               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-37                                  [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-12                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-38                                [1, 256, 18, 32]          1,179,648
|    |    └─SynchronizedBatchNorm2d: 3-39               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-40                                  [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-13                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-41                                [1, 256, 18, 32]          1,179,648
|    |    └─SynchronizedBatchNorm2d: 3-42               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-43                                  [1, 256, 18, 32]          --
|    └─Sequential: 2-14                                 [1, 256, 1, 1]            --
|    |    └─AdaptiveAvgPool2d: 3-44                     [1, 512, 1, 1]            --
|    |    └─Conv2d: 3-45                                [1, 256, 1, 1]            131,072
|    |    └─SynchronizedBatchNorm2d: 3-46               [1, 256, 1, 1]            512
|    |    └─ReLU: 3-47                                  [1, 256, 1, 1]            --
|    └─Conv2d: 2-15                                     [1, 256, 18, 32]          327,680
|    └─SynchronizedBatchNorm2d: 2-16                    [1, 256, 18, 32]          512
|    └─ReLU: 2-17                                       [1, 256, 18, 32]          --
|    └─Dropout: 2-18                                    [1, 256, 18, 32]          --
├─Decoder: 1-3                                          [1, 2, 36, 64]            --
|    └─Conv2d: 2-19                                     [1, 48, 36, 64]           12,288
|    └─SynchronizedBatchNorm2d: 2-20                    [1, 48, 36, 64]           96
|    └─ReLU: 2-21                                       [1, 48, 36, 64]           --
|    └─Sequential: 2-22                                 [1, 2, 36, 64]            --
|    |    └─Conv2d: 3-48                                [1, 256, 36, 64]          700,416
|    |    └─SynchronizedBatchNorm2d: 3-49               [1, 256, 36, 64]          512
|    |    └─ReLU: 3-50                                  [1, 256, 36, 64]          --
|    |    └─Dropout: 3-51                               [1, 256, 36, 64]          --
|    |    └─Conv2d: 3-52                                [1, 256, 36, 64]          589,824
|    |    └─SynchronizedBatchNorm2d: 3-53               [1, 256, 36, 64]          512
|    |    └─ReLU: 3-54                                  [1, 256, 36, 64]          --
|    |    └─Dropout: 3-55                               [1, 256, 36, 64]          --
|    |    └─Conv2d: 3-56                                [1, 2, 36, 64]            514
=========================================================================================================
Total params: 40,732,178
Trainable params: 40,732,178
Non-trainable params: 0
Total mult-adds (G): 24.74
=========================================================================================================
Input size (MB): 0.44
Forward/backward pass size (MB): 316.78
Params size (MB): 162.93
Estimated Total Size (MB): 480.15
=========================================================================================================

\end{verbatim}

\section{inferenceOutlines}

Here we look at details of the Boundary Detection network
\begin{verbatim}


print(self.model)
DeepLab(
  (backbone): DRN(
    (layer0): Sequential(
      (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)
      (1): SynchronizedBatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer1): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer2): Sequential(
      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): SynchronizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer6): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn2): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): SynchronizedBatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer7): Sequential(
      (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
      (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer8): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (aspp): ASPP(
    (aspp1): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (aspp2): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (aspp3): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (aspp4): _ASPPModule(
      (atrous_conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)
      (bn): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (global_avg_pool): Sequential(
      (0): AdaptiveAvgPool2d(output_size=(1, 1))
      (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU()
    )
    (conv1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (decoder): Decoder(
    (conv1): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn1): SynchronizedBatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
    (last_conv): Sequential(
      (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.1, inplace=False)
      (8): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)

summary(self.model, input_size=(1, 3, 144, 256))
Out[5]: 
=========================================================================================================
Layer (type:depth-idx)                                  Output Shape              Param #
=========================================================================================================
├─DRN: 1-1                                              [1, 512, 18, 32]          --
|    └─Sequential: 2-1                                  [1, 16, 144, 256]         --
|    |    └─Conv2d: 3-1                                 [1, 16, 144, 256]         2,352
|    |    └─SynchronizedBatchNorm2d: 3-2                [1, 16, 144, 256]         32
|    |    └─ReLU: 3-3                                   [1, 16, 144, 256]         --
|    └─Sequential: 2-2                                  [1, 16, 144, 256]         --
|    |    └─Conv2d: 3-4                                 [1, 16, 144, 256]         2,304
|    |    └─SynchronizedBatchNorm2d: 3-5                [1, 16, 144, 256]         32
|    |    └─ReLU: 3-6                                   [1, 16, 144, 256]         --
|    └─Sequential: 2-3                                  [1, 32, 72, 128]          --
|    |    └─Conv2d: 3-7                                 [1, 32, 72, 128]          4,608
|    |    └─SynchronizedBatchNorm2d: 3-8                [1, 32, 72, 128]          64
|    |    └─ReLU: 3-9                                   [1, 32, 72, 128]          --
|    └─Sequential: 2-4                                  [1, 256, 36, 64]          --
|    |    └─Bottleneck: 3-10                            [1, 256, 36, 64]          64,768
|    |    └─Bottleneck: 3-11                            [1, 256, 36, 64]          70,400
|    |    └─Bottleneck: 3-12                            [1, 256, 36, 64]          70,400
|    └─Sequential: 2-5                                  [1, 512, 18, 32]          --
|    |    └─Bottleneck: 3-13                            [1, 512, 18, 32]          379,392
|    |    └─Bottleneck: 3-14                            [1, 512, 18, 32]          280,064
|    |    └─Bottleneck: 3-15                            [1, 512, 18, 32]          280,064
|    |    └─Bottleneck: 3-16                            [1, 512, 18, 32]          280,064
|    └─Sequential: 2-6                                  [1, 1024, 18, 32]         --
|    |    └─Bottleneck: 3-17                            [1, 1024, 18, 32]         1,512,448
|    |    └─Bottleneck: 3-18                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-19                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-20                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-21                            [1, 1024, 18, 32]         1,117,184
|    |    └─Bottleneck: 3-22                            [1, 1024, 18, 32]         1,117,184
|    └─Sequential: 2-7                                  [1, 2048, 18, 32]         --
|    |    └─Bottleneck: 3-23                            [1, 2048, 18, 32]         6,039,552
|    |    └─Bottleneck: 3-24                            [1, 2048, 18, 32]         4,462,592
|    |    └─Bottleneck: 3-25                            [1, 2048, 18, 32]         4,462,592
|    └─Sequential: 2-8                                  [1, 512, 18, 32]          --
|    |    └─Conv2d: 3-26                                [1, 512, 18, 32]          9,437,184
|    |    └─SynchronizedBatchNorm2d: 3-27               [1, 512, 18, 32]          1,024
|    |    └─ReLU: 3-28                                  [1, 512, 18, 32]          --
|    └─Sequential: 2-9                                  [1, 512, 18, 32]          --
|    |    └─Conv2d: 3-29                                [1, 512, 18, 32]          2,359,296
|    |    └─SynchronizedBatchNorm2d: 3-30               [1, 512, 18, 32]          1,024
|    |    └─ReLU: 3-31                                  [1, 512, 18, 32]          --
├─ASPP: 1-2                                             [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-10                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-32                                [1, 256, 18, 32]          131,072
|    |    └─SynchronizedBatchNorm2d: 3-33               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-34                                  [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-11                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-35                                [1, 256, 18, 32]          1,179,648
|    |    └─SynchronizedBatchNorm2d: 3-36               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-37                                  [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-12                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-38                                [1, 256, 18, 32]          1,179,648
|    |    └─SynchronizedBatchNorm2d: 3-39               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-40                                  [1, 256, 18, 32]          --
|    └─_ASPPModule: 2-13                                [1, 256, 18, 32]          --
|    |    └─Conv2d: 3-41                                [1, 256, 18, 32]          1,179,648
|    |    └─SynchronizedBatchNorm2d: 3-42               [1, 256, 18, 32]          512
|    |    └─ReLU: 3-43                                  [1, 256, 18, 32]          --
|    └─Sequential: 2-14                                 [1, 256, 1, 1]            --
|    |    └─AdaptiveAvgPool2d: 3-44                     [1, 512, 1, 1]            --
|    |    └─Conv2d: 3-45                                [1, 256, 1, 1]            131,072
|    |    └─SynchronizedBatchNorm2d: 3-46               [1, 256, 1, 1]            512
|    |    └─ReLU: 3-47                                  [1, 256, 1, 1]            --
|    └─Conv2d: 2-15                                     [1, 256, 18, 32]          327,680
|    └─SynchronizedBatchNorm2d: 2-16                    [1, 256, 18, 32]          512
|    └─ReLU: 2-17                                       [1, 256, 18, 32]          --
|    └─Dropout: 2-18                                    [1, 256, 18, 32]          --
├─Decoder: 1-3                                          [1, 3, 36, 64]            --
|    └─Conv2d: 2-19                                     [1, 48, 36, 64]           12,288
|    └─SynchronizedBatchNorm2d: 2-20                    [1, 48, 36, 64]           96
|    └─ReLU: 2-21                                       [1, 48, 36, 64]           --
|    └─Sequential: 2-22                                 [1, 3, 36, 64]            --
|    |    └─Conv2d: 3-48                                [1, 256, 36, 64]          700,416
|    |    └─SynchronizedBatchNorm2d: 3-49               [1, 256, 36, 64]          512
|    |    └─ReLU: 3-50                                  [1, 256, 36, 64]          --
|    |    └─Dropout: 3-51                               [1, 256, 36, 64]          --
|    |    └─Conv2d: 3-52                                [1, 256, 36, 64]          589,824
|    |    └─SynchronizedBatchNorm2d: 3-53               [1, 256, 36, 64]          512
|    |    └─ReLU: 3-54                                  [1, 256, 36, 64]          --
|    |    └─Dropout: 3-55                               [1, 256, 36, 64]          --
|    |    └─Conv2d: 3-56                                [1, 3, 36, 64]            771
=========================================================================================================
Total params: 40,732,435
Trainable params: 40,732,435
Non-trainable params: 0
Total mult-adds (G): 24.74
=========================================================================================================
Input size (MB): 0.44
Forward/backward pass size (MB): 316.79
Params size (MB): 162.93
Estimated Total Size (MB): 480.17
=========================================================================================================

\end{verbatim}

\section{librerealsense installation}
These steps follow the procedure described in the librerealsense repository (\cite{librealsense2021}) on Ubuntu 18.04
\begin{verbatim}
# Register the server's public key
sudo apt-key adv --keyserver keys.gnupg.net --recv-key F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE ||
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-key
F6E65AC044F831AC80A06380C8B3A55A6F3EFCDE 
# Add the server to the list of repositories
# Ubuntu 18 LTS:
sudo add-apt-repository "deb https://librealsense.intel.com/Debian/apt-repo bionic main" -u
# Install the libraries
sudo apt-get install librealsense2-dkms
sudo apt-get install librealsense2-utils
# Optionally install the developer and debug packages
sudo apt-get install librealsense2-dev
sudo apt-get install librealsense2-dbg
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Running the realsense live demo
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Running the realsense live demo}
Once all required libraries have been installed, the system must be rebooted. Then, a stream started:
\begin{verbatim}
~/git/cleargrasp/live_demo/realsense$ ./build/realsense    
\end{verbatim}
Once the stream is running, the live demo may be started:
\begin{verbatim}
~/git/cleargrasp/live_demo$ python live_demo.py -c config/config.yaml
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% tcpflow
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{tcpflow}
tcpflow (\cite{tcpflowElson2013}, \cite{garfinkel2013passive}) is able to capture data packets, transmitted using the TCP (\cite{rfc793}) host-to-host protocol (which provides a process-to-process communication service) and store the data in a human readable format, such that it may be analysed and debugged. For this study, it is used to reconstruct and record data transmissions between the depth camera stream and the prediction engine. 

\begin{verbatim}
sudo apt-get install -y tcpflow    
\end{verbatim}

tcpflow can then be run to monitor port 50010:
\begin{verbatim}
sudo tcpflow -i lo -c port 50010  
\end{verbatim}

\section{VLC Viewer}
Used to view .avi video capture format. To install:
\begin{verbatim}
$ sudo snap install vlc
\end{verbatim}

\section{Kazam}
Used for screen captures. To install:
\begin{verbatim}
$ sudo apt install kazam    
\end{verbatim}
To run:
\begin{verbatim}
$ kazam
\end{verbatim}
To record, place kazam pop-up over monitor to be recorded, then 













